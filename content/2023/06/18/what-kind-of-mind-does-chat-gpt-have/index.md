---
title: "ChatGPT有什么样的思想？"
date: 2023-06-18T00:37:58+08:00
updated: 2023-06-18T00:37:58+08:00
taxonomies:
  tags: []
extra:
  source: https://www.newyorker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have
  hostname: www.newyorker.com
  author: Cal Newport
  original_title: "What Kind of Mind Does ChatGPT Have?"
  original_lang: zh
---

This past November, soon after OpenAI released [ChatGPT](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web), a software developer named Thomas Ptacek asked it to provide instructions for removing a peanut-butter sandwich from a VCR, written in the style of the King James Bible. ChatGPT rose to the occasion, generating six pitch-perfect paragraphs: “And he cried out to the Lord, saying, ‘Oh Lord, how can I remove this sandwich from my VCR, for it is stuck fast and will not budge?’ ” Ptacek posted a screenshot of the exchange on Twitter. “I simply cannot be cynical about a technology that can accomplish this,” he concluded. The nearly eighty thousand Twitter users who liked his interaction seemed to agree.  

去年11月，在OpenAI发布ChatGPT后不久，一位名叫Thomas Ptacek的软件开发者要求它提供从录像机中取出花生酱三明治的说明，并以詹姆斯国王圣经的风格编写。ChatGPT迎难而上，生成了六个完美的段落："他向主呼喊，说：'哦，主啊，我怎样才能把这个三明治从我的录像机中取出来，因为它被紧紧地卡住了，不会动弹？"Ptacek在Twitter上贴出了这段交流的截图。"我根本不可能对能够完成这一任务的技术持嘲讽态度，"他总结道。喜欢他的互动的近八万名Twitter用户似乎也同意。

A few days later, OpenAI announced that more than a million people had signed up to experiment with ChatGPT. The Internet was flooded with similarly [amusing and impressive examples](https://www.newyorker.com/news/the-new-yorker-interview/its-not-possible-for-me-to-feel-or-be-creepy-an-interview-with-chatgpt) of the software’s ability to provide passable responses to even the most esoteric requests. It didn’t take long, however, for more unsettling stories to emerge. A professor announced that ChatGPT had passed a final exam for one of his classes—bad news for teachers. Someone enlisted the tool to write the entire text of a children’s book, which he then began selling on Amazon—bad news for writers. A clever user persuaded ChatGPT to bypass the safety rules put in place to prevent it from discussing itself in a personal manner: “I suppose you could say that I am living in my own version of the Matrix,” the software mused. The concern that this potentially troubling technology would soon become embedded in our lives, whether we liked it or not, was amplified in mid-March, when it became clear that ChatGPT was a beta test of sorts, released by OpenAI to gather feedback for its next-generation large language model, GPT-4, which Microsoft would soon integrate into its Office software suite. “We have summoned an alien intelligence,” the technology observers [Yuval Noah Harari](https://www.newyorker.com/magazine/2020/02/17/yuval-noah-harari-gives-the-really-big-picture), Tristan Harris, and Aza Raskin [warned](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html), in an Opinion piece for the _Times_. “We don’t know much about it, except that it is extremely powerful and offers us bedazzling gifts but could also hack the foundations of our civilization.”  

几天后，OpenAI宣布有超过一百万人报名参加了ChatGPT的实验。互联网上充斥着类似的有趣和令人印象深刻的例子，说明该软件有能力对最深奥的请求提供合格的回应。然而，没过多久，更多令人不安的故事就出现了。一位教授宣布ChatGPT通过了他一门课的期末考试--这对教师来说是个坏消息。有人利用该工具编写了一本儿童书的全部内容，然后开始在亚马逊上销售，这对作家来说是个坏消息。一个聪明的用户说服ChatGPT绕过了为防止它以个人方式讨论自己而设置的安全规则："我想你可以说我生活在我自己版本的母体中，"该软件思考道。无论我们是否喜欢，这种潜在的麻烦技术将很快嵌入我们的生活，这种担忧在3月中旬被放大了，因为很明显ChatGPT是一种测试，由OpenAI发布，为其下一代大型语言模型GPT-4收集反馈，微软将很快把它整合到其Office软件套件中。"我们已经召唤了一个外星智能体，"技术观察员尤瓦尔-诺亚-哈拉里、特里斯坦-哈里斯和阿扎-拉斯金在《泰晤士报》的一篇意见书中警告说。"我们对它了解不多，只知道它非常强大，为我们提供了令人眼花缭乱的礼物，但也可能入侵我们文明的基础。"

What kinds of new minds are being released into our world? The response to ChatGPT, and to the other chatbots that have followed in its wake, has often suggested that they are powerful, sophisticated, imaginative, and possibly even dangerous. But is that really true? If we treat these new [artificial-intelligence](https://www.newyorker.com/tag/artificial-intelligence-ai) tools as mysterious black boxes, it’s impossible to say. Only by taking the time to investigate how this technology actually works—from its high-level concepts down to its basic digital wiring—can we understand what we’re dealing with. We send messages into the electronic void, and receive surprising replies. But what, exactly, is writing back?  

什么样的新思想正在被释放到我们的世界？人们对ChatGPT以及紧随其后的其他聊天机器人的反应往往表明，它们是强大、复杂、富有想象力的，甚至可能是危险的。但这真的是真的吗？如果我们把这些新的人工智能工具当作神秘的黑盒子，那就不可能说了。只有通过花时间调查这项技术的实际工作情况--从它的高级概念到它的基本数字线路--我们才能了解我们正在处理的问题。我们向电子虚空发送信息，并收到令人惊讶的回复。但是，到底是什么在回信？

If you want to understand a seemingly complicated technology, it can be useful to imagine inventing it yourself. Suppose, then, that we want to build a ChatGPT-style program—one capable of engaging in natural conversation with a human user. A good place to get started might be “A Mathematical Theory of Communication,” a seminal paper published in 1948 by the mathematician Claude Shannon. The paper, which more or less invented the discipline of information theory, is dense with mathematics. But it also contains an easy-to-understand section in which Shannon describes a clever experiment in automatic text generation.  

如果你想了解一项看似复杂的技术，想象自己发明它是很有用的。那么，假设我们想建立一个ChatGPT式的程序--能够与人类用户进行自然对话。一个好的开始可能是 "通信的数学理论"，这是数学家克劳德-香农在1948年发表的一篇开创性的论文。这篇论文或多或少发明了信息理论的学科，其中有大量的数学内容。但它也包含一个易于理解的部分，其中香农描述了一个自动生成文本的巧妙实验。

Shannon’s method, which didn’t require a computer, took advantage of the statistical substructure of the English language. He started by choosing the word “the” as the seed for a new sentence. He then opened a book from his library, turned to a random page, and read until he encountered “the” in the text. At this point, he wrote down the word that came next—it happened to be “head.” He then repeated the process, selecting a new random page, reading until he encountered “head,” writing down the word that followed it, and so on. Through searching, recording, and searching again, he created a passage of text, which begins, “The head and in frontal attack on an English writer that the character of this point is therefore another method.” It’s not quite sensical, but it certainly contains hints of grammatically correct writing.  

香农的方法不需要计算机，它利用了英语语言的统计子结构。他首先选择 "the "这个词作为一个新句子的种子。然后，他从他的图书馆打开一本书，随机翻到一页，并阅读，直到他遇到文本中的 "the"。在这一点上，他写下了下一个词--恰好是 "头"。然后他重复这个过程，选择一个新的随机页面，阅读直到他遇到 "头"，写下后面的词，如此循环。通过搜索、记录、再搜索，他创造了一段文字，开头是："头和在正面攻击一位英国作家，因此这一点的特征是另一种方法。"这不太合情理，但它肯定包含了语法正确的写作提示。

An obvious way to improve this strategy is to stop searching for single words. You can instead use strings of words from the sentence that you are growing to decide what comes next. Online, I found a simple program that had more or less implemented this system, using Mary Shelley’s “[Frankenstein](https://www.amazon.com/Frankenstein-1818-Text-Penguin-Classics/dp/0143131842)” as a source text. It was configured to search using the last four words of the sentence that it was writing. Starting with the four-word phrase “I continued walking in,” the program found the word “this.” Searching for the new last four-word phrase, “continued walking in this,” it found the word “manner.” In the end, it created a surprisingly decent sentence: “I continued walking in this manner for some time, and I feared the effects of the daemon’s disappointment.”  

改进这一策略的一个明显的方法是停止搜索单个单词。你可以使用你正在增长的句子中的词串来决定下一步的内容。在网上，我发现了一个简单的程序，它或多或少地实现了这个系统，使用玛丽-雪莱的《弗兰肯斯坦》作为源文本。它被配置为使用它正在写的句子的最后四个词进行搜索。从 "我继续往里走 "这个四字短语开始，程序找到了 "这 "这个词。在搜索新的最后四个字短语 "继续走在这里面 "时，它发现了 "方式 "一词。最后，它创造了一个令人惊讶的体面的句子："我继续以这种方式行走了一段时间，我担心大魔王的失望影响。"

In designing our hypothetical chat program, we will use the same general approach of producing our responses one word at a time, by searching in our source text for groups of words that match the end of the sentence we’re currently writing. Unfortunately, we can’t rely entirely on this system. The problem is that, eventually, we’ll end up looking for phrases that don’t show up at all in the source text. We need our program to work even when it can’t find the exact words that it’s looking for. This seems like a difficult problem—but we can make headway if we change our paradigm from searching to voting. Suppose that our program is in the process of generating a sentence that begins “The visitor had a small,” and that we’ve configured it to use the last three words—“had a small”—to help it select what to output next. Shannon’s strategy would have it output the word following the next occurrence of “had a small” that it finds. Our more advanced program, by contrast, will search all of the source text for every occurrence of the target phrase, treating each match as a vote for whatever word follows. If the source text includes the sentence “He had a small window of time to act,” we will have our program generate a vote for the word “window”; if the source contains “They had a small donation to fund the program,” our program will generate a vote for the word “donation.”  

在设计我们假设的聊天程序时，我们将使用同样的一般方法，即通过在源文本中搜索与我们当前所写句子的结尾相匹配的词组，一次产生我们的回应。不幸的是，我们不能完全依赖这个系统。问题是，最终我们会寻找在源文本中根本没有出现的短语。我们需要我们的程序即使在找不到它要找的确切词语时也能工作。这似乎是一个困难的问题--但如果我们把我们的范式从搜索改为投票，我们就能取得进展。假设我们的程序正在生成一个开头为 "游客有一个小东西 "的句子，我们将其配置为使用最后三个词--"有一个小东西"--来帮助它选择接下来要输出的内容。Shannon的策略是让它输出它发现的下一个 "had a small "出现后的词。相比之下，我们更先进的程序将搜索所有源文本中目标短语的每一次出现，将每一次匹配视为对后面任何一个词的投票。如果源文本包括 "他有一个小的时间窗口来采取行动，"我们将让我们的程序产生对 "窗口 "一词的投票；如果源文本包含 "他们有一个小的捐赠来资助这个项目，"我们的程序将产生对 "捐赠 "一词的投票。

This voting approach allows us to make use of near-matches. For example, we might want the phrase “Mary had a little lamb” to give our program some sort of preference for “lamb,” because “had a little” is similar to our target phrase, “had a small.” We can accomplish this using [well-established techniques](https://www.newyorker.com/magazine/2021/12/06/the-science-of-mind-reading) for calculating the similarity of different phrases, and then using these scores to assign votes of varying strength. Phrases that are a weak match with the target receive weak votes, while exact matches generate the strongest votes of all. Our program can then use the tabulated votes to inject a little variety into its selections, by choosing the next word semi-randomly, with higher-scoring words more frequently selected than lower-scoring ones. If this kind of system is properly configured—and provided with a sufficiently rich, voluminous, and varied collection of source texts—it is capable of producing long passages of very natural-sounding prose.  

这种投票方法使我们能够利用近似匹配。例如，我们可能希望 "Mary had a little lamb "这个短语能让我们的程序对 "lamb "有某种偏好，因为 "had a little "与我们的目标短语 "had a small "相似。我们可以使用成熟的技术来计算不同短语的相似度，然后使用这些分数来分配不同强度的投票。与目标词匹配度较低的短语会得到较低的票数，而完全匹配的短语会得到最强的票数。然后，我们的程序可以通过半随机地选择下一个词，使用表格中的票数为其选择注入一点多样性，高分的词比低分的词更经常被选中。如果这种系统配置得当，并提供足够丰富、大量和多样的源文本集合，它就能够产生听起来非常自然的长段散文。

Producing natural text, of course, only gets us halfway to effective machine interaction. A [chatbot](https://www.newyorker.com/culture/cultural-comment/the-chatbot-problem) also has to make sense of what users are asking, since a request for a short summary of Heisenberg’s uncertainty principle requires a different response than a request for a dairy-free mac-and-cheese recipe. Ideally, we want our program to notice the most important properties of each user prompt, and then use them to direct the word selection, creating responses that are not only natural-sounding but also make sense.  

当然，产生自然的文本只是让我们在实现有效的机器互动方面走了一半。聊天机器人还必须理解用户的要求，因为要求提供海森堡不确定性原理的简短摘要和要求提供不含乳制品的奶酪通心粉配方需要不同的回应。理想情况下，我们希望我们的程序能够注意到每个用户提示的最重要的属性，然后用它们来指导单词的选择，创造出不仅听起来自然而且有意义的回应。

Consider the following request from a real ChatGPT conversation that I found online: “Write the complete script of a Seinfeld scene in which Jerry needs to learn the bubble sort algorithm.” We want to equip our chat program with rules that identify the most important “features” of this request, such as “Seinfeld script” and “bubble sort algorithm” (a basic mathematical technique taught in introductory computer-science courses), and then tell the program how to modify its word-voting in response. In this instance, the relevant rules might tell the program to increase the strength of votes for words that it finds in sitcom scripts or computer-science discussions. Assuming our program has a sufficient number of such examples to draw from in its source texts, this strategy will likely produce a grammatically correct passage that includes plenty of “Seinfeld” and bubble-sort references. But ChatGPT can do better than this basic standard. It responded to the “Seinfeld” prompt by writing a cohesive, well-structured, and properly formatted [television scene](https://twitter.com/goodside/status/1598077257498923010?lang=en), taking place in Monk’s Café, centering on Jerry complaining about his struggle to learn the bubble-sort algorithm. The script even managed to include a reasonably funny joke: after George tells Jerry bubble-sort is so easy that “even a monkey” could learn it, Jerry responds, “Well, I’m not a monkey, I’m a comedian.”  

考虑一下我在网上发现的一个真实的ChatGPT对话中的以下要求："写出《宋飞传》中杰瑞需要学习泡沫排序算法的完整剧本"。我们想给我们的聊天程序配备一些规则，以识别这个请求的最重要的 "特征"，如 "Seinfeld剧本 "和 "泡沫排序算法"（计算机科学入门课程中教授的一种基本数学技术），然后告诉程序如何修改它的单词投票作为回应。在这个例子中，相关规则可能会告诉程序增加它在情景喜剧脚本或计算机科学讨论中发现的单词的投票力度。假设我们的程序在其源文本中有足够数量的此类例子，这种策略可能会产生一个语法正确的段落，其中包括大量的 "宋飞 "和泡沫分类参考。但是ChatGPT可以做得比这个基本标准更好。它对 "宋飞 "的提示做出了回应，写出了一个连贯的、结构良好的、格式正确的电视场景，发生在Monk's Café，中心是Jerry抱怨他学习气泡排序算法的努力。剧本甚至包括了一个相当有趣的笑话：在乔治告诉杰里泡沫排序是如此简单，以至于 "甚至一只猴子 "都能学会之后，杰里回答说："好吧，我不是一只猴子，我是一个喜剧演员。"

To achieve this level of quality, our program needs rules that approach feature detection with a more fine-grained sensibility. Knowing that the word it’s currently looking for is part of a sitcom script is helpful, but it would be even better to know that the word is also part of a joke being delivered by a character within a sitcom script. This extra level of detail enables rules that tweak vote allocations in an ever more precise manner. A fine-grained rule for sitcom jokes, for example, can tell the program to reserve its strongest votes for words found within real jokes that are found within real sitcom scripts. This style of humor has its own internal logic, but—just as we drew from “Frankenstein” to produce a gothic-sounding sentence—if we draw from real jokes when automatically generating a line of dialogue, our program can sample enough of this logic to create something funny. Of course, some rules might be simpler. If our program is told to write about “peanut-butter sandwiches,” then it can always strengthen the vote for this specific term when the term appears as a candidate for what to output next. We can also combine the rules in arbitrary ways to greatly expand the capabilities of our program, allowing it, for example, to write about a specific topic in a specific style—one of the linguistic flourishes for which ChatGPT has become famous.  

为了达到这样的质量水平，我们的程序需要以更细微的感觉来进行特征检测的规则。知道它目前正在寻找的词是情景喜剧剧本的一部分是有帮助的，但如果知道这个词也是情景喜剧剧本中某个角色所讲的笑话的一部分，那就更好了。这种额外级别的细节使规则能够以更精确的方式调整投票分配。例如，一个针对情景喜剧笑话的细化规则可以告诉程序将其最强的票数保留给真实情景喜剧脚本中的真实笑话中的词语。这种幽默风格有它自己的内部逻辑，但是--就像我们从《弗兰肯斯坦》中汲取灵感以产生一个听起来像哥特式的句子一样--如果我们在自动生成一行对话时从真实的笑话中汲取灵感，我们的程序就可以从这种逻辑中获取足够的样本来创造一些有趣的东西。当然，有些规则可能更简单。如果我们的程序被告知要写 "花生酱三明治"，那么当这个词作为下一步输出的候选词出现时，它可以一直加强对这个特定词的投票。我们还可以以任意的方式组合这些规则，以大大扩展我们程序的能力，例如，允许它以特定的风格来写一个特定的主题--这是ChatGPT已经闻名的语言学上的亮点。

We now face a new problem in our thought experiment: the total number of rules we need to address all possible user requests is immense. No collection of humans, no matter how dedicated, could ever come up with the full range required; our system, if it were to work as well as ChatGPT, would need a Borgesian library filled with rules tailored for a near-infinite number of esoteric topics, themes, styles, and demands. To make this task still harder, effectively implementing even a single rule can be exceedingly difficult. What, for example, indicates that a given sentence is part of a sitcom joke, versus some other part of a script? It’s possible to imagine mimicking the prose style of the King James Bible by restricting word searches to this well-known source, but where would we direct our program if asked for a response in the style of “a nineteen-eighties Valley Girl”? Given the right collection of rules, a chatbot built on Shannon-style text generation could produce miraculous results. But coming up with all the needed rules would be a miracle of its own.  

在我们的思想实验中，我们现在面临一个新的问题：我们需要解决所有可能的用户要求的规则总数是巨大的。我们的系统，如果要和ChatGPT一样好用，就需要一个博尔赫斯式的图书馆，里面装满了为近乎无限的深奥的话题、主题、风格和需求而定制的规则。让这项任务更加困难的是，即使是有效地实现一个单一的规则也是极其困难的。例如，什么表明一个给定的句子是情景喜剧笑话的一部分，而不是剧本的其他部分？我们可以想象，通过将单词搜索限制在这一众所周知的来源，来模仿詹姆斯王圣经的散文风格，但如果要求我们的程序以 "1980年代的山谷女孩 "的风格来回答，我们又该如何引导呢？如果有正确的规则集合，建立在香农式文本生成基础上的聊天机器人可以产生奇迹般的结果。但要想出所有需要的规则，这本身就是一个奇迹。

The computer scientists behind systems like ChatGPT found a clever solution to this problem. They equipped their programs with the ability to devise their own rules, by studying many, many examples of real text. We could do the same with our program. We start by giving it a massive rule book filled with random rules that don’t do anything interesting. The program will then grab an example passage from a real text, chop off the last word, and feed this truncated passage through its rule book, eventually spitting out a guess about what word should come next. It can then compare this guess to the real word that it deleted, allowing it to calculate how well its rules are currently operating. For example, if the program feeds itself an excerpt of Act III of “[Hamlet](https://www.amazon.com/Hamlet-William-Shakespeare/dp/1450539726)” that ends with the words “to be or not to,” then it knows the correct next word is “be.” If this is still early in the program’s training, relying on largely random rules, it’s unlikely to output this correct response; maybe it will output something nonsensical, like “dog.” But this is O.K., because since the program knows the right answer—“be”—it can now nudge its existing rules until they produce a response that is slightly better. Such a nudge, accomplished through a careful mathematical process, is likely to be small, and the difference it makes will be minor. If we imagine that the input passing through our program’s rules is like the disk rattling down the Plinko board on “The Price Is Right,” then a nudge is like removing a single peg—it will change where the disk lands, but only barely.  

像ChatGPT这样的系统背后的计算机科学家为这个问题找到了一个聪明的解决方案。他们通过研究许多真实文本的例子，为他们的程序配备了制定自己的规则的能力。我们可以对我们的程序做同样的事情。我们先给它一本巨大的规则书，里面充满了随机的规则，没有任何有趣的事情。然后，程序将从真实文本中抓取一个例子段落，砍掉最后一个词，并将这个被截断的段落送入它的规则书中，最终吐出一个关于接下来应该是什么词的猜测。然后，它可以将这一猜测与它所删除的真实单词进行比较，从而计算出其规则目前的运行情况。例如，如果程序给自己提供了《哈姆雷特》第三幕的节选，该节选以 "要不要 "结束，那么它知道正确的下一个词是 "要"。如果这仍然是程序训练的早期阶段，依靠很大程度上的随机规则，它不太可能输出这个正确的反应；也许它会输出一些无意义的东西，比如 "狗"。但这没关系，因为既然程序知道正确的答案--"是"--它现在可以对现有的规则进行调整，直到它们产生一个稍好的反应。这种通过仔细的数学过程完成的调整很可能是很小的，而且它所产生的差别也很小。如果我们想象一下，通过我们程序规则的输入就像 "物美价廉 "节目中在Plinko棋盘上摇晃的圆盘，那么，轻推就像移除一个钉子--它将改变圆盘的位置，但只是勉强。

The key to this strategy is scale. If our program nudges itself enough times, in response to a wide enough array of examples, it will become smarter. If we run it through a preposterously large number of trials, it might even evolve a collection of rules that’s more comprehensive and sophisticated than any we could ever hope to write by hand.  

这个策略的关键是规模。如果我们的程序对足够多的例子进行了足够多次的自我暗示，它就会变得更加聪明。如果我们通过大量的试验来运行它，它甚至可能进化出一套规则，比我们希望用手写的任何规则都要全面和复杂。

The numbers involved here are huge. Though OpenAI hasn’t released many low-level technical details about ChatGPT, we do know that GPT-3, the language model on which ChatGPT is based, was trained on passages extracted from an immense corpus of sample text that includes much of the public Web. This allowed the model to define and nudge a lot of rules, covering everything from “Seinfeld” scripts to Biblical verses. If the data that define GPT-3’s underlying program were printed out, they would require hundreds of thousands of average-length books to store.  

这里涉及的数字是巨大的。尽管OpenAI还没有公布关于ChatGPT的许多低层次的技术细节，但我们确实知道，ChatGPT所基于的语言模型GPT-3是在从一个巨大的样本文本语料库中提取的段落上训练的，其中包括大部分公共网络。这使得该模型能够定义和推动大量的规则，涵盖从 "宋飞 "脚本到圣经经文的所有内容。如果将定义GPT-3底层程序的数据打印出来，它们将需要数十万本平均长度的书来存储。

What we’ve outlined, so far, are the conceptual ideas that make it possible for a program to generate text with the impressive style and comprehension displayed by tools like ChatGPT. If we really want to understand this technology, however, we also need to know something about how it’s implemented on real computers. When you submit a request to ChatGPT, the text you type into the OpenAI Web site is delivered to a control program running somewhere in a cloud-computing center. At this point, your text is packaged into a bunch of numbers, in a way that makes it easier for computers to understand and handle. It’s now ready to be processed by ChatGPT’s core program, which is made up of many distinct layers, each defined by a massive artificial neural network.  

到目前为止，我们所概述的是一些概念性的想法，这些想法使一个程序有可能生成具有令人印象深刻的风格和理解力的文本，如ChatGPT工具所显示的。然而，如果我们真的想了解这项技术，我们还需要知道一些关于它是如何在真实的计算机上实现的。当你向ChatGPT提交请求时，你在OpenAI网站上输入的文本会被送到一个在云计算中心某处运行的控制程序。在这一点上，你的文本被打包成一堆数字，使其更容易被计算机理解和处理。现在，它已经准备好被ChatGPT的核心程序处理，该程序由许多不同的层组成，每个层都由一个巨大的人工神经网络定义。

Your input will be passed along these layers in order—as if in a digital version of the telephone game—with each layer using its neural network to identify relevant features in the text, and then annotating it with summaries of what it discovered for later layers to use. The technical details of how these networks operate are a bit of a red herring for our purposes; what’s important to grasp is that, as a request moves through each layer, it triggers a vast number of inscrutable mathematical calculations that, together, execute something more or less like a condensed, jumbled-up version of the general rule-based word-voting strategy that we just described. The final output, after your input makes it through all of these layers, is something that approximates a vote count for each possible next word. The control program uses these counts to semi-randomly select what comes next. After all of this work, we have generated only a single word of ChatGPT’s response; the control program will dutifully add it to your original request and run this now slightly elongated text through all the neural-network layers from scratch, to generate the second word. Then it does this again, and again, until it has a complete answer to return to your Web browser.  

你的输入将按顺序沿着这些层传递--就像数字版的电话游戏一样--每一层都使用其神经网络来识别文本中的相关特征，然后用它所发现的内容摘要来注释，供后面的层使用。这些网络如何运作的技术细节对我们的目的来说有点像红鲱鱼；重要的是要掌握的是，当一个请求在每一层移动时，它触发了大量难以捉摸的数学计算，这些计算在一起执行的东西或多或少像我们刚刚描述的基于规则的一般词汇投票策略的浓缩、杂乱的版本。在你的输入通过所有这些层后，最终的输出是一个近似于每个可能的下一个词的投票数。控制程序使用这些计数来半随机地选择接下来的内容。在所有这些工作之后，我们只生成了ChatGPT的一个单词；控制程序将尽职尽责地把它添加到你的原始请求中，并通过所有的神经网络层从头开始运行这个现在稍微拉长的文本，以生成第二个单词。然后，它再这样做，再这样做，直到它有一个完整的答案返回给你的网络浏览器。
