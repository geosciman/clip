---
title: 为什么人工智能会拯救世界
date: 2023-06-08T17:46:34+08:00
updated: 2023-06-08T17:46:34+08:00
taxonomies:
  tags: 
extra:
  source: https://a16z.com/2023/06/06/ai-will-save-the-world/
  hostname: a16z.com
  author: Marc Andreessen
  original_title: Why AI Will Save the World
  original_lang: en-US
---

The era of Artificial Intelligence is here, and boy are people freaking out.  
人工智能时代来了，男孩们都吓坏了。

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.  
幸运的是，我来这里是为了带来好消息：人工智能不会毁灭世界，实际上可能会拯救世界。

First, a short description of what AI _is_: The application of mathematics and software code to teach computers how to understand, synthesize, and generate knowledge in ways similar to how people do it. AI is a computer program like any other – it runs, takes input, processes, and generates output. AI’s output is useful across a wide range of fields, ranging from coding to medicine to law to the creative arts. It is owned by people and controlled by people, like any other technology.  
首先，简单介绍一下人工智能是什么：应用数学和软件代码教计算机如何以类似于人类的方式理解、综合和生成知识。 AI 是一种与其他任何计算机程序一样的计算机程序——它运行、接受输入、处理并生成输出。 AI 的输出在广泛的领域都很有用，从编码到医学到法律再到创意艺术。与任何其他技术一样，它由人拥有并由人控制。

A shorter description of what AI _isn’t_: Killer software and robots that will spring to life and decide to murder the human race or otherwise ruin everything, like you see in [the movies](https://movieweb.com/best-killer-robot-horror-movies-ranked/)  
对人工智能不是什么的简短描述：杀手软件和机器人会复活并决定谋杀人类或以其他方式毁掉一切，就像你在电影中看到的那样.

An even shorter description of what AI _could be_: A way to make everything we care about better.  
对人工智能可能是什么的更简短描述：一种让我们关心的一切变得更好的方法。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)

Why AI Can Make Everything We Care About Better  
为什么人工智能可以让我们关心的一切变得更好**

The most validated core conclusion of social science across many decades and thousands of studies is that _human_ intelligence makes a very broad range of life outcomes better. Smarter people have better outcomes in almost every domain of activity: academic achievement, job performance, occupational status, income, creativity, physical health, longevity, learning new skills, managing complex tasks, leadership, entrepreneurial success, conflict resolution, reading comprehension, financial decision making, understanding others’ perspectives, creative arts, parenting outcomes, and life satisfaction.  
经过几十年和数千项研究，社会科学最有效的内核结论是，人类智慧可以改善范围广泛的生活结果。更聪明的人几乎在每个活动领域都有更好的结果：学业成绩、工作表现、职业地位、收入、创造力、身体健康、长寿、学习新技能、管理复杂任务、领导力、创业成功、冲突解决、阅读理解、财务决策制定、理解他人的观点、创造性艺术、育儿成果和生活满意度。

Further, human intelligence is the lever that we have used for millennia to create the world we live in today: science, technology, math, physics, chemistry, medicine, energy, construction, transportation, communication, art, music, culture, philosophy, ethics, morality. Without the application of intelligence on all these domains, we would all still be living in mud huts, scratching out a meager existence of subsistence farming. Instead we have used our intelligence to raise our standard of living on the order of 10,000X over the last 4,000 years.  
此外，人类智慧是我们几千年来用来创造我们今天生活的世界的杠杆：科学、技术、数学、物理、化学、医学、能源、建筑、交通、通信、艺术、音乐、文化、哲学、道德，道德。如果没有在所有这些领域应用智能，我们都将仍然住在泥屋里，勉强维持生计农业的微薄生存。相反，在过去的 4,000 年里，我们利用我们的智慧将我们的生活水平提高了 10,000 倍。

What AI offers us is the opportunity to profoundly _augment_ human intelligence to make all of these outcomes of intelligence – and many others, from the creation of new medicines to ways to solve climate change to technologies to reach the stars – much, much better from here.  
AI 为我们提供的是深刻增强人类智能的机会，使所有这些智能成果——以及许多其他成果，从新药的创造到解决气候变化的方法，再到到达星星的技术——从这里变得更好.

AI augmentation of human intelligence has already started – AI is already around us in the form of computer control systems of many kinds, is now rapidly escalating with AI Large Language Models like ChatGPT, and will accelerate very quickly from here – _if we let it_  
AI 对人类智能的增强已经开始——AI 已经以多种计算机控制系统的形式存在于我们身边，现在正随着 ChatGPT 等 AI 大型语言模型迅速升级，并且从这里开始加速——如果我们允许的话.

In our new era of AI:  
在我们的人工智能新时代：

-   Every child will have an AI tutor that is infinitely patient, infinitely compassionate, infinitely knowledgeable, infinitely helpful. The AI tutor will be by each child’s side every step of their development, helping them maximize their potential with the machine version of infinite love.  
    每个孩子都会有一位无限耐心、无限慈悲、无限知识、无限帮助的AI导师。 AI导师将陪伴在每个孩子成长的每一步，用无限爱的机器版帮助他们发挥最大潜能。
-   Every person will have an AI assistant/coach/mentor/trainer/advisor/therapist that is infinitely patient, infinitely compassionate, infinitely knowledgeable, and infinitely helpful. The AI assistant will be present through all of life’s opportunities and challenges, maximizing every person’s outcomes.  
    每个人都会有一位无限耐心、无限同情、无限知识和无限帮助的 AI 助手/教练/导师/培训师/顾问/治疗师。人工智能助手将在生活中的所有机遇和挑战中出现，最大限度地提高每个人的成果。
-   Every scientist will have an AI assistant/collaborator/partner that will greatly expand their scope of scientific research and achievement. Every artist, every engineer, every businessperson, every doctor, every caregiver will have the same in their worlds.  
    每个科学家都会有一个 AI 助手/合作者/伙伴，这将极大地扩展他们的科学研究和成果范围。每个艺术家、每个工程师、每个商人、每个医生、每个护理人员都会在他们的世界中拥有相同的东西。
-   Every leader of people – CEO, government official, nonprofit president, athletic coach, teacher – will have the same. The magnification effects of better decisions by leaders across the people they lead are enormous, so this intelligence augmentation may be the most important of all.  
    每个人的领袖——首席执行官、政府官员、非营利组织主席、体育教练、教师——都会有同样的东西。领导者做出的更好决策对他们所领导的人的放大效应是巨大的，因此这种智力增强可能是最重要的。
-   Productivity growth throughout the economy will accelerate dramatically, driving economic growth, creation of new industries, creation of new jobs, and wage growth, and resulting in a new era of heightened material prosperity across the planet.  
    整个经济体的生产率增长将急剧加快，推动经济增长、新产业的创造、新就业机会的创造和工资增长，并导致全球物质繁荣的新时代到来。
-   Scientific breakthroughs and new technologies and medicines will dramatically expand, as AI helps us further decode the laws of nature and harvest them for our benefit.  
    随着人工智能帮助我们进一步破译自然法则并为我们谋取利益，科学突破以及新技术和药物将显着扩展。
-   The creative arts will enter a golden age, as AI-augmented artists, musicians, writers, and filmmakers gain the ability to realize their visions far faster and at greater scale than ever before.  
    创意艺术将进入黄金时代，因为人工智能增强的艺术家、音乐家、作家和电影制作人将能够比以往任何时候更快、更大规模地实现他们的愿景。
-   I even think AI is going to improve warfare, when it has to happen, by reducing wartime death rates dramatically. Every war is characterized by terrible decisions made under intense pressure and with sharply limited information by very limited human leaders. Now, military commanders and political leaders will have AI advisors that will help them make much better strategic and tactical decisions, minimizing risk, error, and unnecessary bloodshed.  
    我什至认为人工智能将在必要时通过大幅降低战时死亡率来改善战争。每一场战争的特点都是在巨大的压力下做出可怕的决定，并且由非常有限的人类领导人提供极其有限的信息。现在，军事指挥官和政治领导人将拥有人工智能顾问，帮助他们做出更好的战略和战术决策，最大限度地减少风险、错误和不必要的流血事件。
-   In short, anything that people do with their natural intelligence today can be done much better with AI, and we will be able to take on new challenges that have been impossible to tackle without AI, from curing all diseases to achieving interstellar travel.  
    简而言之，当今人们利用其自然智能所做的任何事情都可以通过 AI 做得更好，我们将能够应对如果没有 AI 就无法应对的新挑战，从治愈所有疾病到实现星际旅行。
-   And this isn’t just about intelligence! Perhaps the most underestimated quality of AI is how _humanizing_ it can be. AI art gives people who otherwise lack technical skills the freedom to [create and share their artistic ideas](https://www.forbes.com/sites/tjmccue/2023/01/23/midjourney-ai-based-art-generator-creates-dazzling-images-from-words/?sh=737b460a5f61). Talking to an empathetic AI friend really does improve [their ability to handle adversity](https://www.npr.org/sections/health-shots/2023/01/19/1147081115/therapy-by-chatbot-the-promise-and-challenges-in-using-ai-for-mental-health). And AI medical chatbots are already [more empathetic](https://www.usatoday.com/story/news/health/2023/05/01/chatbots-show-more-empathy-than-doctors-in-answeringpatient-questions-with-more-empathy-than-doctors/70170816007/) than their human counterparts. Rather than making the world harsher and more mechanistic, infinitely patient and sympathetic AI will make the world warmer and nicer.  
    这不仅仅是关于智力！也许人工智能最被低估的品质是它的人性化程度。人工智能艺术让缺乏技术技能的人可以自由地创造和分享他们的艺术想法。与善解人意的 AI 朋友交谈确实可以提高他们处理逆境的能力。人工智能医疗聊天机器人已经比人类同行更具同理心。无限耐心和富有同情心的人工智能不会让世界变得更加严酷和机械化，而是会让世界变得更加温暖和美好。

The stakes here are high. The opportunities are profound. AI is quite possibly the most important – and best – thing our civilization has ever created, certainly on par with electricity and microchips, and probably beyond those.  
这里的风险很高。机遇是深远的。人工智能很可能是我们文明所创造的最重要——也是最好的——东西，当然可以与电力和微芯片相提并论，甚至可能超越它们。

The development and proliferation of AI – far from a risk that we should fear – is a moral obligation that we have to ourselves, to our children, and to our future.  
人工智能的发展和扩散——远非我们应该担心的风险——是我们对自己、对我们的孩子和对我们的未来所承担的道德义务。

We should be living in a much better world with AI, and now we can.  
有了人工智能，我们应该生活在一个更美好的世界中，现在我们可以做到。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****So Why The Panic? 那么为什么恐慌？**

In contrast to this positive view, the public conversation about AI is presently shot through with hysterical fear and paranoia.  
与这种积极观点形成鲜明对比的是，目前关于 AI 的公众对话充斥着歇斯底里的恐惧和偏执狂。

We hear claims that AI will variously kill us all, ruin our society, take all our jobs, cause crippling inequality, and enable bad people to do awful things.  
我们听说人工智能会以各种方式杀死我们所有人、毁掉我们的社会、夺走我们所有的工作、造成严重的不平等，并让坏人做出可怕的事情。

What explains this divergence in potential outcomes from near utopia to horrifying dystopia?  
如何解释这种从近乎乌托邦到可怕的反乌托邦的潜在结果的差异？

Historically, every new technology that matters, from electric lighting to automobiles to radio to the Internet, has sparked a _moral panic_ – a [social contagion](https://en.wikipedia.org/wiki/Moral_panic) that convinces people the new technology is going to destroy the world, or society, or both. The fine folks at [Pessimists Archive](https://pessimistsarchive.org/) have documented these technology-driven moral panics over the decades; their history makes the pattern vividly clear. It turns out this present panic is [not even the first for AI](https://newsletter.pessimistsarchive.org/p/the-original-ai-doomer-dr-norbert)  
从历史上看，每一项重要的新技术，从电灯到汽车，再到收音机再到互联网，都引发了道德恐慌——一种让人们相信新技术将摧毁世界、社会或两者的社会传染病。几十年来，悲观主义者档案馆的优秀人士记录了这些技术驱动的道德恐慌；他们的历史使这种模式生动清晰。事实证明，目前的恐慌甚至不是人工智能的第一次.

Now, it is certainly the case that many new technologies have led to bad outcomes – often the same technologies that have been otherwise enormously beneficial to our welfare. So it’s not that the mere existence of a moral panic means there is nothing to be concerned about.  
现在，可以肯定的是，许多新技术导致了糟糕的结果——通常是同样的技术在其他方面对我们的福祉产生了巨大的好处。因此，仅仅存在道德恐慌并不意味着没有什么可担心的。

But a moral panic is by its very nature _irrational_ – it takes what may be a legitimate concern and inflates it into a level of hysteria that ironically makes it harder to confront actually serious concerns.  
但道德恐慌本质上是非理性的——它把可能是合理的担忧夸大到歇斯底里的程度，具有讽刺意味的是，这使得人们更难面对真正严重的担忧。

And wow do we have a [full-blown moral panic about AI](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/) right now.  
哇，我们现在对人工智能有全面的道德恐慌吗？

This moral panic is already being used as a motivating force by a variety of actors to demand policy action – new AI restrictions, regulations, and laws. These actors, who are making [extremely dramatic public statements](https://nypost.com/2023/01/26/rogue-ai-could-kill-everyone-scientists-warn/) about the dangers of AI – feeding on and further inflaming moral panic – all present themselves as selfless champions of the public good.  
这种道德恐慌已经被各种参与者用作动力，要求采取政策行动——新的 AI 限制、法规和法律。这些演员就人工智能的危险发表了极其戏剧性的公开声明——助长并进一步煽动道德恐慌——所有这些人都把自己表现为公共利益的无私捍卫者。

But are they? 但他们是吗？

And are they right or wrong?  
他们是对还是错？

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****The Baptists And Bootleggers Of AI  
人工智能的浸信会和走私者**

Economists have observed a [longstanding pattern](https://en.wikipedia.org/wiki/Bootleggers_and_Baptists) in reform movements of this kind. The actors within movements like these fall into two categories – “Baptists” and “Bootleggers” – drawing on the historical example of the [prohibition of alcohol in the United States in the 1920’s](https://en.wikipedia.org/wiki/Prohibition_in_the_United_States)  
经济学家观察到这种改革运动的长期模式。这些运动中的参与者分为两类——“浸信会”和“走私者”——借鉴了 1920 年代美国禁酒的历史例子:

-   “Baptists” are the true believer social reformers who legitimately feel – deeply and emotionally, if not rationally – that new restrictions, regulations, and laws are required to prevent societal disaster. For alcohol prohibition, these actors were often literally [devout Christians](https://en.wikipedia.org/wiki/Carrie_Nation) who felt that alcohol was destroying the moral fabric of society. For AI risk, these actors are true believers that AI presents one or another existential risks – strap them to a polygraph, they really mean it.  
    “浸信会”是真正的信徒社会改革者，他们合理地——深刻地和情绪化地，如果不是理性地——认为需要新的限制、法规和法律来防止社会灾难。对于禁酒令，这些演员通常是真正虔诚的基督徒，他们认为酒精正在破坏社会的道德结构。对于 AI 风险，这些参与者真正相信 AI 会带来一种或另一种存在风险——将他们绑在测谎仪上，他们是认真的。
-   “Bootleggers” are the self-interested opportunists who stand to financially profit by the imposition of new restrictions, regulations, and laws that insulate them from competitors. For alcohol prohibition, these were the [literal bootleggers](https://en.wikipedia.org/wiki/Category:Bootleggers) who made a fortune selling illicit alcohol to Americans when legitimate alcohol sales were banned. For AI risk, these are CEOs who stand to make more money if regulatory barriers are erected that form a cartel of government-blessed AI vendors protected from new startup and open source competition – the software version of “too big to fail” banks.  
    “走私者”是自私自利的机会主义者，他们通过实施新的限制、法规和法律将他们与竞争对手隔离开来，从而在经济上获利。对于禁酒，这些是字面上的私酒贩子，他们在禁止合法酒类销售时向美国人出售非法酒类发了财。对于 AI 风险，如果创建监管壁垒，这些 CEO 将赚更多的钱，这些壁垒形成了一个由政府支持的 AI 供应商组成的卡特尔，保护它们免受新创业公司和开源竞争的影响——“大到不能倒”银行的软件版本。

A cynic would suggest that some of the apparent Baptists are also Bootleggers – specifically the ones paid to attack AI by their [universities](https://hai.stanford.edu/news/new-report-assesses-progress-and-risks-artificial-intelligence), [think tanks](https://www.brookings.edu/blog/up-front/2023/05/22/the-us-government-should-regulate-ai/), [activist groups](https://www.humanetech.com/podcast/the-ai-dilemma), and [media outlets](https://www.washingtonpost.com/opinions/2023/05/26/ai-regulation-congress-risk/). If you are [paid a salary](https://projects.propublica.org/nonprofits/organizations/582565917) or [receive grants](https://www.fhi.ox.ac.uk/grant-announcement/) to foster AI panic…you are probably a Bootlegger.  
愤世嫉俗的人会认为，一些明显的浸信会教徒也是走私者——特别是那些被他们的大学、智囊团、活动家团体和媒体机构付钱攻击人工智能的人。如果你拿薪水或接受助学金来助长 AI 恐慌……你可能是走私者。

The problem with the Bootleggers is that they _win_. The Baptists are naive ideologues, the Bootleggers are cynical operators, and so the result of reform movements like these is often that the Bootleggers get what they want – regulatory capture, insulation from competition, the formation of a cartel – and the Baptists are left wondering where their drive for social improvement went so wrong.  
Bootleggers 的问题在于他们赢了。浸信会是天真的空想家，走私者是愤世嫉俗的经营者，所以像这样的改革运动的结果往往是走私者得到他们想要的东西——监管俘获、竞争隔离、卡特尔的形成——而浸信会则感到疑惑他们推动社会进步的动力在哪里出错了。

We just lived through a stunning example of this – banking reform after the 2008 global financial crisis. The Baptists told us that we needed new laws and regulations to break up the “too big to fail” banks to prevent such a crisis from ever happening again. So Congress passed the Dodd-Frank Act of 2010, which was marketed as satisfying the Baptists’ goal, but in reality was coopted by the Bootleggers – the big banks. The result is that the same banks that were “too big to fail” in 2008 are _much, much larger_ now.  
我们刚刚经历了一个令人震惊的例子——2008 年全球金融危机后的银行业改革。浸信会告诉我们，我们需要新的法律法规来拆分“大到不能倒”的银行，以防止此类危机再次发生。因此，国会通过了 2010 年的多德-弗兰克法案，该法案标榜为满足浸信会的目标，但实际上却被走私者——大银行所采用。结果是，2008 年“大到不能倒”的银行现在规模大得多。

So in practice, even when the Baptists are genuine – and even when the Baptists are _right_ – they are used as cover by manipulative and venal Bootleggers to benefit themselves.   
所以在实践中，即使浸信会是真诚的——即使浸信会是正确的——他们也被操纵和贪污的私酒贩子用作掩护，以使自己受益。

And this is what is happening in the drive for AI regulation right now.  
这就是目前在推动 AI 监管方面正在发生的事情。

However, it isn’t sufficient to simply identify the actors and impugn their motives. We should consider the arguments of both the Baptists and the Bootleggers on their merits.  
然而，仅仅确定演员身份并质疑他们的动机是不够的。我们应该考虑浸信会和走私者的论点。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****AI Risk #1: Will AI Kill Us All?  
AI 风险 #1：AI 会杀死我们所有人吗？**

The first and original AI doomer risk is that AI will decide to literally kill humanity.  
第一个也是最初的 AI 末日风险是 AI 将决定真正杀死人类。

The fear that technology of our own creation will rise up and destroy us is deeply coded into our culture. The Greeks expressed this fear in the Prometheus Myth – Prometheus brought the destructive power of fire, and more generally technology (“techne”), to man, for which Prometheus was condemned to perpetual torture by the gods. Later, Mary Shelley gave us moderns our own version of this myth in her novel _Frankenstein, or, The Modern Prometheus_, in which we develop the technology for eternal life, which then rises up and seeks to destroy us. And of course, no AI panic newspaper story is complete without a still image of a gleaming red-eyed killer robot from James Cameron’s _Terminator_ films.  
对我们自己创造的技术会兴起并摧毁我们的恐惧深深地融入了我们的文化中。希腊人在普罗米修斯神话中表达了这种恐惧——普罗米修斯给人类带来了火的破坏力，更普遍的是技术（“techne”），为此普罗米修斯被众神判处永久折磨。后来，玛丽·雪莱在她的小说《弗兰肯斯坦》或《现代普罗米修斯》中为我们现代人提供了这个神话的版本，我们在其中开发永生技术，然后崛起并试图摧毁我们。当然，如果没有詹姆斯·卡梅隆的终结者电影中闪闪发光的红眼杀人机器人的静止图像，任何关于 AI 恐慌的报纸报道都是不完整的。

The presumed evolutionary purpose of this mythology is to motivate us to seriously consider potential risks of new technologies – fire, after all, can indeed be used to burn down entire cities. But just as fire was also the foundation of modern civilization as used to keep us warm and safe in a cold and hostile world, this mythology ignores the far greater upside of most – all? – new technologies, and in practice inflames destructive emotion rather than reasoned analysis. Just because premodern man freaked out like this doesn’t mean we have to; we can apply rationality instead.  
这个神话的假定进化目的是激励我们认真考虑新技术的潜在风险——毕竟，火确实可以用来烧毁整个城市。但正如火也是现代文明的基础，在寒冷和充满敌意的世界中让我们保持温暖和安全一样，这个神话忽略了大多数 - 全部？ – 新技术，在实践中激起了破坏性的情绪，而不是理性的分析。仅仅因为前现代人像这样吓坏了并不意味着我们必须这样做；我们可以改用理性。

My view is that the idea that AI will decide to literally kill humanity is a profound [category error](https://en.wikipedia.org/wiki/Category_mistake). AI is not a living being that has been primed by billions of years of evolution to participate in the battle for the survival of the fittest, as animals are, and as we are. It is math – code – computers, built by people, owned by people, used by people, controlled by people. The idea that it will at some point develop a mind of its own and decide that it has motivations that lead it to try to kill us is a superstitious handwave.  
我的观点是，人工智能将决定真正杀死人类的想法是一个严重的类别错误。人工智能不是经过数十亿年的进化而准备参与适者生存之战的生物，就像动物和我们一样。它是数学-代码-计算机，由人建造，由人拥有，由人使用，由人控制。它会在某个时候发展出自己的思想并决定它有导致它试图杀死我们的动机的想法是一种迷信的手波。

In short, AI doesn’t _want_, it doesn’t have _goals_, it doesn’t want to _kill you_, because it’s not _alive_. And AI is a machine – is not going to come alive any more than your toaster will.  
简而言之，AI 不想，它没有目标，它不想杀死你，因为它没有生命。人工智能是一台机器——不会像你的烤面包机那样活跃起来。

Now, obviously, there are true believers in killer AI – Baptists – who are gaining a suddenly stratospheric amount of media coverage for their terrifying warnings, some of whom claim to have been studying the topic for decades and say they are now scared out of their minds by what they have learned. Some of these true believers are even [actual](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) [innovators](https://www.bbc.com/news/technology-65760449) of the technology. These actors are arguing for a variety of bizarre and extreme restrictions on AI ranging from a [ban on AI development](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html), all the way up to [military airstrikes on datacenters](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/) and [nuclear war](https://mishtalk.com/economics/to-stop-ai-lunatics-are-willing-to-risk-a-global-nuclear-war). They argue that because people like me cannot rule out future catastrophic consequences of AI, that we must assume a [precautionary](https://en.wikipedia.org/wiki/Precautionary_principle) stance that may require large amounts of physical violence and death in order to prevent potential existential risk.  
现在，很明显，杀手人工智能的真正信徒——浸信会——他们的可怕警告突然获得了大量的媒体报道，其中一些人声称已经研究这个话题几十年了，并说他们现在害怕自己的生活他们所学的思想。其中一些真正的信徒甚至是该技术的实际创新者。这些参与者主张对 AI 实施各种奇怪和极端的限制，从禁止 AI 开发，一直到对数据中心的军事空袭和核战争。他们争辩说，因为像我这样的人不能排除人工智能未来的灾难性后果，我们必须采取预防措施，可能需要大量的身体暴力和死亡，以防止潜在的生存风险。

My response is that their position is non-scientific – What is the testable hypothesis? What would falsify the hypothesis? [How do we know when we are getting into a danger zone?](https://twitter.com/aidangomezzz/status/1651053357719535622?s=46&t=Oa_2uNFzXdquihp6LY7u1Q) These questions go mainly unanswered apart from “You can’t prove it won’t happen!” In fact, these Baptists’ position is _so_ non-scientific and _so_ extreme – a conspiracy theory about math and code – and is already calling for physical violence, that I will do something I would normally not do and question their motives as well.  
我的回答是他们的立场是非科学的——什么是可检验的假设？什么会证伪这个假设？我们怎么知道我们何时进入危险区域？除了“你无法证明它不会发生！”之外，这些问题基本上没有答案。事实上，这些浸信会的立场是如此的不科学和极端——一个关于数学和代码的阴谋论——并且已经在呼吁身体暴力，以至于我会做一些我通常不会做的事情，并质疑他们的动机。

Specifically, I think three things are going on:  
具体来说，我认为有以下三点：

First, recall that John Von Neumann responded to Robert Oppenheimer’s famous hand-wringing about his role creating nuclear weapons – which helped end World War II and prevent World War III – with, “Some people confess guilt to claim credit for the sin.” What is the most dramatic way one can claim credit for the importance of one’s work without sounding overtly boastful? This explains the mismatch between the words and actions of the Baptists who are actually building and funding AI – watch their actions, not their words. (Truman was harsher after meeting with Oppenheimer: [“Don’t let that crybaby in here again.”](https://www.lrb.co.uk/the-paper/v22/n17/steven-shapin/don-t-let-that-crybaby-in-here-again)  
首先，回想一下约翰·冯·诺伊曼回应罗伯特·奥本海默著名的关于他在制造核武器方面的作用——这有助于结束第二次世界大战和防止第三次世界大战——的回应是，“有些人承认有罪以声称自己的罪过。”什么是最引人注目的方式来声称自己的工作的重要性而不是公开吹嘘？这解释了实际上正在构建和资助 AI 的浸信会的言行之间的不匹配——注意他们的行动，而不是他们的话。 （杜鲁门在与奥本海默会面后变得更加严厉：“别再让那个爱哭鬼进来了。”)

Second, some of the Baptists are actually Bootleggers. There is a whole profession of “AI safety expert”, “AI ethicist”, “AI risk researcher”. They are paid to be doomers, and their statements should be processed appropriately.  
其次，一些浸信会实际上是走私者。有一整套“AI安全专家”、“AI伦理学家”、“AI风险研究员”的职业。他们被付钱是注定要失败的，他们的陈述应该得到适当的处理。

Third, [California is justifiably famous for our many thousands of cults](https://www.vanityfair.com/hollywood/2020/09/california-cults-nxivm-the-vow), from EST to the Peoples Temple, from Heaven’s Gate to the Manson Family. Many, although not all, of these cults are harmless, and maybe even serve a purpose for alienated people who find homes in them. But some are very dangerous indeed, and cults have a notoriously hard time straddling the line that ultimately leads to [violence and death](https://en.wikipedia.org/wiki/Peoples_Temple#Mass_murder/suicide_at_Jonestown,_Guyana)  
第三，加利福尼亚以我们数以千计的邪教而闻名，从 EST 到人民圣殿教，从天堂之门到曼森家族。这些邪教中有许多（尽管不是全部）是无害的，甚至可能为那些在其中找到归宿的异化者服务。但有些确实非常危险，众所周知，邪教很难跨越最终导致暴力和死亡的界限.

And the reality, which is obvious to everyone in the Bay Area but probably not outside of it, is that “AI risk” has [developed](https://studio.ribbonfarm.com/p/the-priest-in-the-arena) [into](https://twitter.com/QiaochuYuan/status/1542767419394912256) a [cult](https://www.lesswrong.com/posts/MnFqyPLqbiKL8nSR7/my-experience-at-and-around-miri-and-cfar-inspired-by-zoe), which has suddenly emerged into the daylight of global press attention and the public conversation. This cult has pulled in not just fringe characters, but also some actual industry experts and a not small number of wealthy donors – including, until recently, [Sam Bankman-Fried](https://fortune.com/2022/11/15/sam-bankman-fried-ftx-collapse-a-i-safety-research-effective-altruism-debacle/). And it’s developed a full panoply of cult behaviors and beliefs.  
湾区内的每个人都清楚但湾区外可能并非如此的现实是，“AI 风险”已经发展成为一种邪教，它突然出现在全球媒体关注和公众对话的日光下。这种邪教不仅吸引了边缘人物，还吸引了一些实际的行业专家和不少富有的捐助者——包括直到最近的山姆·班克曼-弗里德 (Sam Bankman-Fried)。它已经发展出一整套的邪教行为和信仰。

This cult is why there are a set of AI risk doomers who [sound so extreme](https://www.youtube.com/watch?v=gA1sNLL6yg4) – it’s not that they actually have secret knowledge that make their extremism logical, it’s that they’ve whipped themselves into a frenzy and really are…extremely extreme.  
这种邪教就是为什么有一组 AI 风险末日论者听起来如此极端的原因——并不是说他们实际上拥有使他们的极端主义合乎逻辑的秘密知识，而是他们已经把自己激怒了，而且真的……非常极端。

It turns out that this type of cult isn’t new – there is a longstanding Western tradition of [millenarianism](https://en.wikipedia.org/wiki/Millenarianism), which generates apocalypse cults. The AI risk cult has all the hallmarks of a millenarian apocalypse cult. From Wikipedia, with additions by me:  
事实证明，这种类型的邪教并不新鲜——西方千禧年主义由来已久，由此产生了末世邪教。人工智能风险崇拜具有千禧年末日崇拜的所有特征。来自维基百科，加上我的补充：

> “Millenarianism is the belief by a group or movement \[AI risk doomers\] in a coming fundamental transformation of society \[the arrival of AI\], after which all things will be changed \[AI utopia, dystopia, and/or end of the world\]. Only dramatic events \[AI bans, airstrikes on datacenters, nuclear strikes on unregulated AI\] are seen as able to change the world \[prevent AI\] and the change is anticipated to be brought about, or survived, by a group of the devout and dedicated. In most millenarian scenarios, the disaster or battle to come \[AI apocalypse, or its prevention\] will be followed by a new, purified world \[AI bans\] in which the believers will be rewarded \[or at least acknowledged to have been correct all along\].”  
> “千禧年主义是一个团体或运动 \[AI risk doomers\] 对即将到来的社会根本变革 \[AI 的到来\] 的信念，之后一切都会改变 \[AI 乌托邦、反乌托邦和/或世界末日\] .只有戏剧性事件 \[AI 禁令、对数据中心的空袭、对不受监管的 AI 的核打击\] 才被视为能够改变世界 \[阻止 AI\]，并且预计这种变化将由一群虔诚和敬业的人带来或幸存下来.在大多数千禧年情景中，灾难或战争即将到来 \[AI 启示，或其预防\] 之后将是一个新的、净化的世界 \[AI 禁令\]，信徒将在其中得到奖励 \[或至少承认一直是正确的\]”

This apocalypse cult pattern is so obvious that I am surprised more people don’t see it.  
这种天启崇拜模式是如此明显，以至于我很惊讶更多的人没有看到它。

Don’t get me wrong, cults are fun to hear about, [their written material is often creative and fascinating](https://hpmor.com/), and their members are engaging at dinner parties and [on TV](https://www.youtube.com/watch?v=hO8aYSApnng). But their extreme beliefs should not determine the future of laws and society – _obviously_ not.  
不要误会我的意思，邪教很有趣，他们的书面材料通常富有创意和引人入胜，而且他们的成员在晚宴和电视上都很活跃。但他们的极端信仰不应该决定法律和社会的未来——显然不是。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****AI Risk #2: Will AI Ruin Our Society?  
AI 风险 #2：AI 会毁掉我们的社会吗？**

The second widely mooted AI risk is that AI will ruin our society, by generating outputs that will be so “harmful”, to use the nomenclature of this kind of doomer, as to cause profound damage to humanity, even if we’re not literally killed.  
第二个广泛讨论的 AI 风险是 AI 会通过产生如此“有害”的输出来破坏我们的社会，使用这种末日毁灭者的术语，对人类造成深远的损害，即使我们不是字面上的杀了。

Short version: If the murder robots don’t get us, the hate speech and misinformation will.  
简短版本：如果谋杀机器人没有抓住我们，那么仇恨言论和错误信息就会。

This is a relatively recent doomer concern that branched off from and somewhat took over the “AI risk” movement that I described above. In fact, the terminology of AI risk recently changed from “AI safety” – the term used by people who are worried that AI would literally kill us – to “AI alignment” – the term used by people who are worried about societal “harms”. The original AI safety people are frustrated by this shift, although they don’t know how to put it back in the box – they now advocate that the _actual_ AI risk topic be renamed “AI notkilleveryoneism”, which has [not yet been widely adopted](https://www.greaterwrong.com/posts/jMzBhCRrr7otmqcvK/notkilleveryoneism-sounds-dumb) but is at least clear.  
这是一个相对较新的末日担忧，它从我上面描述的“AI 风险”运动中分支出来并在某种程度上接管了它。事实上，人工智能风险的术语最近从“人工智能安全”——担心人工智能会真正杀死我们的人使用的术语——变成了“人工智能对齐”——担心社会“危害”的人使用的术语.最初的 AI 安全人士对这种转变感到沮丧，尽管他们不知道如何将其放回原处——他们现在主张将实际的 AI 风险主题更名为“AI notkilleveryoneism”，该主题尚未被广泛采用但至少是清楚的。

The tipoff to the nature of the AI societal risk claim is its own term, “AI alignment”. [Alignment with what?](https://futureoflife.org/ai/align-artificial-intelligence-with-human-values/) Human values. [Whose human values?](https://arxiv.org/pdf/2301.03740.pdf) Ah, that’s where things get tricky.  
AI 社会风险声明的本质是它自己的术语“AI 一致性”。对齐什么？人类价值观。谁的人文价值？啊，这就是事情变得棘手的地方。

As it happens, I have had a front row seat to an analogous situation – the social media “trust and safety” wars. As is [now](https://en.wikipedia.org/wiki/Twitter_Files) [obvious](https://twitter.com/AGAndrewBailey/status/1664286859344719872), social media services have been under massive pressure from governments and activists to ban, restrict, censor, and otherwise suppress a wide range of content for many years. And the same concerns of “hate speech” (and its mathematical counterpart, “algorithmic bias”) and “misinformation” are being [directly transferred](https://cyber.fsi.stanford.edu/io/news/forecasting-potential-misuses-language-models-disinformation-campaigns-and-how-reduce-risk) from the social media context to the new frontier of “AI alignment”.   
碰巧的是，我曾在类似的情况下坐在前排——社交媒体“信任与安全”战争。现在很明显，多年来，社交媒体服务一直承受着来自政府和活动家的巨大压力，要求禁止、限制、审查和以其他方式压制范围广泛的内容。对“仇恨言论”（及其数学对应物“算法偏见”）和“错误信息”的同样担忧正从社交媒体语境直接转移到“人工智能对齐”的新领域。

My big learnings from the social media wars are:  
我从社交媒体大战中学到的重要知识是：

On the one hand, there is no absolutist free speech position. First, every country, including the United States, [makes at least some content illegal](https://en.wikipedia.org/wiki/United_States_free_speech_exceptions). Second, there are certain kinds of content, like child pornography and incitements to real world violence, that are nearly universally agreed to be off limits – legal or not – by virtually every society. So any technological platform that facilitates or generates content – speech – is going to have _some_ restrictions.  
一方面，没有绝对的言论自由立场。首先，包括美国在内的每个国家都至少将某些内容定为非法。其次，有某些类型的内容，例如儿童色情和煽动现实世界中的暴力，几乎每个社会都几乎普遍同意禁止访问这些内容——无论合法与否。因此，任何促进或生成内容（语音）的技术平台都会受到一些限制。

On the other hand, the slippery slope is not a fallacy, it’s an inevitability. Once a framework for restricting even egregiously terrible content is in place – for example, for hate speech, a specific hurtful word, or for misinformation, obviously false claims like “[the Pope is dead](https://www.americamagazine.org/politics-society/2022/07/12/pope-benedict-dead-fake-news-243347)” – a shockingly broad range of [government agencies](https://judiciary.house.gov/sites/evo-subsites/republicans-judiciary.house.gov/files/evo-media-document/2023-04-28-jdj-to-rubin-gec-subpoena-cover-letter.pdf) and [activist pressure groups](https://en.wikipedia.org/wiki/Color_of_Change) and [nongovernmental entities](https://cyber.fsi.stanford.edu/io) will kick into gear and demand ever greater levels of censorship and suppression of whatever speech they view as threatening to society and/or their own personal preferences. They will do this up to and including in ways that are nakedly [felony](https://www.law.cornell.edu/uscode/text/18/241) [crimes](https://www.law.cornell.edu/uscode/text/18/242). This cycle in practice can run apparently forever, with the enthusiastic support of authoritarian hall monitors installed throughout our elite power structures. This has been cascading for a decade in social media and with only [certain](https://twitter.com/home) [exceptions](https://substack.com/) continues to get more fervent all the time.  
另一方面，滑坡并不是谬误，而是必然。一旦限制甚至极其可怕的内容的框架到位——例如，仇恨言论，一个特定的伤害性词，或错误信息，明显是虚假的声明，如“教皇已死”——范围广泛的政府机构和激进主义者的压力团体和非政府实体将开始行动，并要求对他们认为对社会和/或他们自己的个人偏好构成威胁的任何言论进行更严格的审查和压制。他们将以赤裸裸的重罪方式做到这一点。这个循环在实践中显然可以永远运行，在我们精英权力结构中安装的专制大厅监视器的热情支持下。这已经在社交媒体上流传了十年，而且除了某些例外情况之外，这种情况一直在持续变得更加热烈。

And so this is the dynamic that has formed around “AI alignment” now. Its proponents claim the wisdom to engineer AI-generated speech and thought that are good for society, and to ban AI-generated speech and thoughts that are bad for society. Its _opponents_ claim that the thought police are breathtakingly arrogant and presumptuous – and often outright criminal, at least in the US – and in fact are seeking to become a new kind of fused government-corporate-academic authoritarian speech dictatorship ripped straight from the pages of George Orwell’s _1984_  
这就是现在围绕“AI 对齐”形成的动态。它的支持者声称有智慧来设计 AI 生成的对社会有益的言论和思想，并禁止 AI 生成的对社会有害的言论和思想。它的反对者声称，思想警察是惊人的傲慢和专横——而且往往是彻头彻尾的犯罪，至少在美国是这样——事实上，他们正在寻求成为一种新型的政府-企业-学术融合的专制言论专政，直接从乔治·奥威尔的 1984.

As the proponents of both “trust and safety” and “AI alignment” are clustered into the very narrow slice of the global population that characterizes the American coastal elites – which includes many of the people who work in and write about the tech industry – many of my readers will find yourselves primed to argue that dramatic restrictions on AI output are required to avoid destroying society. I will not attempt to talk you out of this now, I will simply state that this is the nature of the demand, and that most people in the world neither agree with your ideology [nor want to see you win](https://www.nytimes.com/2022/03/18/opinion/cancel-culture-free-speech-poll.html)  
由于“信任与安全”和“人工智能一致性”的支持者聚集在全球人口中非常小的一部分，这是美国沿海精英的特征——其中包括许多在科技行业工作和撰写科技行业的人——许多我的读者会发现自己准备争辩说需要对 AI 输出进行严格限制以避免破坏社会。我现在不会试图说服你，我只会说这是需求的本质，世界上大多数人既不同意你的意识形态，也不希望看到你获胜.

If you _don’t_ agree with the prevailing niche morality that is being imposed on both social media and AI via ever-intensifying speech codes, you should also realize that the fight over what AI is allowed to say/generate will be even more important – by a _lot_ – than the fight over social media censorship. AI is highly likely to be the control layer for everything in the world. How it is allowed to operate is going to matter perhaps more than anything else has ever mattered. You should be aware of how a small and isolated coterie of partisan social engineers are trying to determine that right now, under cover of the age-old claim that they are protecting you.  
如果你不同意通过不断强化的语音代码强加给社交媒体和人工智能的主流利基道德，你还应该意识到，关于允许人工智能说/生成什么的斗争将更加重要 –很多 - 而不是围绕社交媒体审查制度的斗争。人工智能极有可能成为世界万物的控制层。它如何被允许运作可能比其他任何事情都更重要。你应该知道一小群孤立的党派社会工程师如何在古老的声称他们正在保护你的掩护下试图确定这一点。

In short, don’t let the thought police suppress AI.  
总之，不要让思想警察打压人工智能。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****AI Risk #3: Will AI Take All Our Jobs?  
AI 风险 #3：AI 会抢走我们所有的工作吗？**

The fear of job loss due variously to mechanization, automation, computerization, or AI has been a recurring panic for hundreds of years, since the original onset of machinery such as the [mechanical loom](https://en.wikipedia.org/wiki/Luddite). Even though every new major technology has led to more jobs at higher wages throughout history, each wave of this panic is accompanied by claims that “this time is different” – _this_ is the time it will finally happen, _this_ is the technology that will finally deliver the hammer blow to human labor. And yet, it never happens.   
自机械织布机等机器最初出现以来，数百年来，人们对因机械化、自动化、计算机化或人工智能而导致失业的恐惧一直是一种反复出现的恐慌。尽管在历史上每一项新的主要技术都以更高的工资带来了更多的工作，但每一波恐慌都伴随着“这次不同”的说法——这是它最终会发生的时间，这是最终会发生的技术对人类劳动进行锤击。然而，它从未发生过。

We’ve been through two such technology-driven unemployment panic cycles in our recent past – the [outsourcing](http://nfap.com/researchactivities/globalsourcing/itemsInterest/AndreesenDobbsCNN_030404.pdf) panic of the 2000’s, and the [automation](https://www.usatoday.com/story/money/2017/11/29/automation-could-kill-73-million-u-s-jobs-2030/899878001/) panic of the 2010’s. Notwithstanding many talking heads, pundits, and even [tech industry executives](https://www.ycombinator.com/blog/basic-income) pounding the table throughout both decades that mass unemployment was near, by late 2019 – right before the onset of COVID – the world had more jobs at higher wages than ever in history.  
在我们最近的过去，我们经历了两次这样的技术驱动的失业恐慌周期——2000 年代的外包恐慌和 2010 年代的自动化恐慌。尽管在过去的几十年里，许多会说话的人、专家，甚至科技行业的高管都在敲桌子说大规模失业迫在眉睫，但到 2019 年底——就在 COVID 爆发之前——世界上的工作岗位比历史上任何时候都多，工资更高。

Nevertheless [this mistaken idea will not die](https://www.marxists.org/history/etol/newspape/isr/vol25/no03/adhoc.html)  
不过这个错误的想法不会消亡.

And sure enough, [it’s back](https://www.theinformation.com/articles/ai-will-destroy-jobs-so-what-are-we-going-to-do-about-it) 果然，它回来了.

_This time_, we _finally_ have the technology that’s going to take all the jobs and render human workers superfluous – _real_ AI. Surely _this time_ history won’t repeat, and AI will cause mass unemployment – and not rapid economic, job, and wage growth – right?  
这一次，我们终于拥有了将取代所有工作并使人类工人变得多余的技术——真正的人工智能。这一次历史肯定不会重演，人工智能将导致大规模失业——而不是经济、就业和工资的快速增长——对吧？

No, that’s not going to happen – and in fact AI, if allowed to develop and proliferate throughout the economy, may cause the most dramatic and sustained economic boom of all time, with correspondingly record job and wage growth – the exact opposite of the fear. And here’s why.  
不，这不会发生——事实上，如果允许人工智能在整个经济中发展和扩散，可能会导致有史以来最剧烈和持续的经济繁荣，相应地创纪录的工作和工资增长——与恐惧完全相反.这就是为什么。

The core mistake the automation-kills-jobs doomers keep making is called the [Lump Of Labor Fallacy](https://en.wikipedia.org/wiki/Lump_of_labour_fallacy). This fallacy is the incorrect notion that there is a fixed amount of labor to be done in the economy at any given time, and either machines do it or people do it – and if machines do it, there will be no work for people to do.  
自动化扼杀工作的厄运论者不断犯的内核错误被称为劳动力谬误。这种谬误是错误的观念，即在任何给定时间经济中都有固定数量的劳动要做，机器做或人做——如果机器做，人就没有工作可做.

The Lump Of Labor Fallacy flows naturally from naive intuition, but naive intuition here is wrong. When technology is applied to production, we get [_productivity growth_](https://en.wikipedia.org/wiki/Productivity) – an increase in output generated by a reduction in inputs. The result is _lower prices_ for goods and services. As prices for goods and services fall, we pay less for them, meaning that we now have _extra spending power_ with which to buy _other things_. This _increases demand_ in the economy, which drives the creation of _new production_ – including new products and new industries – which then creates new jobs for the people who were replaced by machines in prior jobs. The result is a larger economy with higher material prosperity, more industries, more products, and more jobs.  
劳动块谬误自然源于幼稚的直觉，但幼稚的直觉在这里是错误的。当技术应用于生产时，我们会提高生产率——通过减少投入来增加产出。结果是商品和服务的价格降低。随着商品和服务价格的下降，我们为它们支付的费用也会减少，这意味着我们现在拥有额外的消费能力来购买其他东西。这增加了经济中的需求，从而推动了新生产的创造——包括新产品和新产业——然后为那些在以前的工作中被机器取代的人创造了新的就业机会。其结果是一个更大的经济体，拥有更高的物质繁荣、更多的工业、更多的产品和更多的就业机会。

But the good news doesn’t stop there. We also get higher wages. This is because, at the level of the individual worker, the marketplace sets compensation as a function of the [_marginal productivity of the worker_](https://en.wikipedia.org/wiki/Marginal_revenue_productivity_theory_of_wages). A worker in a technology-infused business will be more productive than a worker in a traditional business. The employer will either pay that worker more money as he is now more productive, or another employer will, purely out of self interest. The result is that technology introduced into an industry generally not only increases the number of jobs in the industry but also raises wages.  
但好消息并不止于此。我们也可以获得更高的工资。这是因为，在个体工人的层面上，市场将薪酬设定为工人边际生产率的函数。技术注入型企业的员工比传统企业的员工更有效率。雇主要么支付该工人更多的钱，因为他现在的工作效率更高，要么另一个雇主纯粹出于自身利益。结果是，引入一个行业的技术通常不仅会增加该行业的就业人数，还会提高工资。

To summarize, technology empowers people to be more productive. This causes the prices for existing goods and services to fall, and for wages to rise. This in turn causes economic growth and job growth, while motivating the creation of new jobs and new industries. If a market economy is allowed to function normally and if technology is allowed to be introduced freely, this is a perpetual upward cycle that never ends. For, as Milton Friedman observed, “Human wants and needs are endless” – we always want more than we have. A technology-infused market economy is the way we get closer to delivering everything everyone could conceivably want, but never all the way there. [And that is why technology doesn’t destroy jobs and never will.](https://www.aeaweb.org/articles?id=10.1257/jep.29.3.3)  
总而言之，技术使人们能够提高工作效率。这导致现有商品和服务的价格下降，工资上涨。这反过来又会促进经济增长和就业增长，同时推动创造新的就业机会和新的产业。如果允许市场经济正常运行，如果允许技术自由引进，这是一个永无止境的永恒上升循环。因为，正如米尔顿·弗里德曼 (Milton Friedman) 观察到的那样，“人类的需求是无止境的”——我们想要的总是比我们拥有的更多。一个技术注入的市场经济是我们更接近于提供每个人都可以想象到的一切的方式，但从来没有完全实现。这就是为什么技术不会而且永远不会破坏工作。[](https://sci-hub.wf/10.1257/jep.29.3.3)

These are such mindblowing ideas for people who have not been exposed to them that it may take you some time to wrap your head around them. But I swear I’m not making them up – in fact you can read all about them in standard economics textbooks. I recommend the chapter [_The Curse of Machinery_](https://fee.org/resources/economics-in-one-lesson#calibre_link-31) in Henry Hazlitt’s _Economics In One Lesson_, and Frederic Bastiat’s satirical _Candlemaker’s Petition_ to blot out the sun due to its unfair competition with the lighting industry, [here modernized for our times](https://www.aei.org/carpe-diem/the-candlemakers-petition-revised-and-modernized-for-todays-climate-of-rising-trade-protectionism/)  
对于那些没有接触过它们的人来说，这些想法是如此令人兴奋，你可能需要一些时间来理解它们。但我发誓我没有编造它们——事实上，你可以在标准经济学教科书中读到所有关于它们的内容。我推荐 Henry Hazlitt 的《经济学一课》中的机械诅咒一章，以及 Frederic Bastiat 讽刺的 Candlemaker's Petition to blot sun 因为它与照明行业的不公平竞争，这里为我们的时代进行了现代化改造.

_But this time is different_, you’re thinking. _This time, with AI, we have the technology that can replace ALL human labor._  
但这次不一样，你在想。这一次，有了人工智能，我们拥有了可以取代所有人类劳动的技术。

But, using the principles I described above, think of what it would mean for literally all existing human labor to be replaced by machines.  
但是，使用我上面描述的原则，想一想从字面上看，所有现有的人类劳动都将被机器取代意味着什么。

It would mean a takeoff rate of economic productivity growth that would be absolutely stratospheric, far beyond any historical precedent. Prices of existing goods and services would drop across the board to virtually zero. Consumer welfare would skyrocket. Consumer spending power would skyrocket. New demand in the economy would explode. Entrepreneurs would create dizzying arrays of new industries, products, and services, and employ as many people _and_ AI as they could as fast as possible to meet all the new demand.  
这将意味着经济生产力增长的起飞速度绝对是惊人的，远远超过任何历史先例。现有商品和服务的价格将全面下降至几乎为零。消费者福利将飙升。消费者的消费能力将飙升。经济中的新需求将会爆发。企业家们将创造出令人眼花缭乱的新产业、新产品和新服务，并尽可能快地雇佣尽可能多的人和人工智能来满足所有新需求。

Suppose AI once again replaces _that_ labor? The cycle would repeat, driving consumer welfare, economic growth, and job and wage growth even higher. It would be a straight spiral up to a material utopia that neither Adam Smith or Karl Marx ever dared dream of.   
假设人工智能再次取代劳动力？循环将重复，推动消费者福利、经济增长以及就业和工资增长更高。这将是一个直线上升的物质乌托邦，这是亚当·斯密或卡尔·马克思都不敢梦想的。

We should be so lucky. 我们应该如此幸运。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****AI Risk #4: Will AI Lead To Crippling Inequality?  
AI 风险 #4：AI 会导致严重的不平等吗？**

Speaking of Karl Marx, the concern about AI taking jobs segues directly into the next claimed AI risk, which is, OK, Marc, suppose AI _does_ take all the jobs, either for bad or for good. Won’t that result in massive and crippling wealth inequality, as the owners of AI reap all the economic rewards and regular people get nothing?  
说到卡尔·马克思，对人工智能抢走工作的担忧直接引向了下一个声称的人工智能风险，那就是，好吧，马克，假设人工智能确实抢走了所有的工作，无论是好是坏。这会不会导致严重的财富不平等，因为人工智能的所有者获得了所有的经济回报，而普通人一无所获？

As it happens, this was a central claim of Marxism, that the owners of the means of production – the bourgeoisie – would inevitably steal all societal wealth from the people who do the actual  work – the proletariat. This is another fallacy that simply will not die no matter how often it’s disproved by reality. But let’s drive a stake through its heart anyway.  
事实上，这是马克思主义的内核主张，即生产资料的所有者——资产阶级——将不可避免地从从事实际工作的人——无产阶级那里窃取所有社会财富。这是另一个谬论，无论它被现实推翻多少次，它都不会消亡。但不管怎样，让我们在它的心脏上插一根木桩吧。

The flaw in this theory is that, as the owner of a piece of technology, it’s not in your own interest to keep it to yourself – in fact the opposite, it’s in your own interest to sell it to as many customers as possible. The largest market in the world for any product is the entire world, all 8 billion of us. And so in reality, every new technology – even ones that start by selling to the rarefied air of high-paying big companies or wealthy consumers – rapidly proliferates until it’s in the hands of the largest possible mass market, ultimately everyone on the planet.  
这个理论的缺陷在于，作为一项技术的所有者，将它留给自己并不符合你自己的利益——事实上恰恰相反，将它卖给尽可能多的客户符合你自己的利益。世界上任何产品最大的市场是整个世界，我们 80 亿人。因此在现实中，每一项新技术——即使是那些最初是向高薪大公司或富有消费者的稀薄空气出售的技术——都会迅速扩散，直到它到达尽可能大的大众市场，最终到达地球上的每个人的手中。

The classic example of this was Elon Musk’s so-called [“secret plan”](https://www.tesla.com/blog/secret-tesla-motors-master-plan-just-between-you-and-me) – which he naturally published openly – for Tesla in 2006:  
这方面的典型例子是埃隆·马斯克 (Elon Musk) 在 2006 年为特斯拉制定的所谓“秘密计划”——他自然而然地公开了这一计划：

> Step 1, Build \[expensive\] sports car  
> 第 1 步，打造 \[昂贵\] 跑车
> 
> Step 2, Use that money to build an affordable car  
> 第 2 步，用这笔钱制造一辆负担得起的汽车
> 
> Step 3, Use that money to build an even more affordable car  
> 第 3 步，用这笔钱制造一辆更实惠的汽车

…which is of course exactly what he’s done, becoming the richest man in the world as a result.  
......当然这正是他所做的，结果成为世界上最富有的人。

That last point is key. Would Elon be even richer if he only sold cars to rich people today? No. Would he be even richer than that if he only made cars for himself? Of course not. No, he maximizes his own profit by selling to the largest possible market, the world.  
最后一点是关键。如果埃隆今天只卖汽车给富人，他会更富有吗？不，如果他只为自己制造汽车，他会比这更富有吗？当然不是。不，他通过向世界这个最大的可能市场销售来最大化自己的利润。

In short, everyone gets the thing – as we saw in the past with not just cars but also electricity, radio, computers, the Internet, mobile phones, and search engines. The makers of such technologies are highly motivated to drive down their prices until everyone on the planet can afford them. This is precisely what is already happening in AI – it’s why you can use state of the art generative AI not just at low cost but even _for free_ today in the form of Microsoft Bing and Google Bard – and it is what will continue to happen. Not because such vendors are foolish or generous but precisely because they are greedy – they want to maximize the size of their market, which maximizes their profits.  
简而言之，每个人都得到了东西——正如我们在过去看到的，不仅有汽车，还有电力、收音机、电脑、互联网、手机和搜索引擎。此类技术的制造商非常积极地降低价格，直到地球上的每个人都能负担得起。这正是 AI 已经发生的事情——这就是为什么你不仅可以低成本使用最先进的生成 AI，甚至可以免费使用 Microsoft Bing 和 Google Bard 的形式——而且这将继续发生。不是因为这些供应商愚蠢或慷慨，而是因为他们贪婪——他们想要最大化他们的市场规模，从而最大化他们的利润。

So what happens is the opposite of technology driving centralization of wealth – individual customers of the technology, ultimately including everyone on the planet, are empowered instead, and [capture most of the generated value](https://www.nber.org/digest/oct04/who-gains-innovation). As with prior technologies, the companies that build AI – assuming they have to function in a free market – will compete furiously to make this happen.  
因此，发生的情况与技术推动财富集中化相反——技术的个人客户，最终包括地球上的每个人，反而被赋予了权力，并获得了大部分产生的价值。与现有技术一样，构建人工智能的公司——假设它们必须在自由市场中运作——将激烈竞争以实现这一目标。

Marx was wrong then, and he’s wrong now.  
马克思当时错了，现在也错了。

This is _not_ to say that inequality is not an issue in our society. It is, it’s just not being driven by technology, [it’s being driven by the reverse](https://www.aei.org/carpe-diem/chart-of-the-day-or-century-8/), by the sectors of the economy that are the most _resistant_ to new technology, that have the most government intervention to _prevent_ the adoption of new technology like AI – specifically housing, education, and health care. The actual risk of AI and inequality is not that AI will _cause_ more inequality but rather that [we will not allow AI to be used to _reduce_ inequality](https://pmarca.substack.com/p/why-ai-wont-cause-unemployment)  
这并不是说不平等不是我们社会的问题。是的，它不是由技术驱动，而是被相反的驱动，由对新技术最抵触的经济部门，政府干预最多以防止采用人工智能等新技术——特别是住房、教育和医疗保健。人工智能和不平等的实际风险不是人工智能会导致更多的不平等，而是我们不允许人工智能被用来减少不平等.

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****AI Risk #5: Will AI Lead To Bad People Doing Bad Things?  
AI 风险 #5：AI 会导致坏人做坏事吗？**

So far I have explained why four of the five most often proposed risks of AI are not actually real – AI will not come to life and kill us, AI will not ruin our society, AI will not cause mass unemployment, and AI will not cause an ruinous increase in inequality. But now let’s address the fifth, the one I actually agree with: AI will make it easier for bad people to do bad things.  
到目前为止，我已经解释了为什么五个最常被提及的 AI 风险中有四个实际上并不真实——AI 不会复活并杀死我们，AI 不会毁灭我们的社会，AI 不会导致大规模失业，AI 不会导致不平等的破坏性增加但现在让我们谈谈第五点，我非常同意的一点：人工智能将使坏人更容易做坏事。

In some sense this is a tautology. Technology is a tool. Tools, starting with fire and rocks, can be used to do good things – cook food and build houses – and bad things – burn people and bludgeon people. Any technology can be used for good or bad. Fair enough. And AI will make it easier for criminals, terrorists, and hostile governments to do bad things, no question.  
从某种意义上说，这是一个重言式。技术是一种工具。工具，从火和石头开始，可以用来做好事——做饭和盖房子——也可以用来做坏事——烧人和打人。任何技术都可以用于好事或坏事。很公平。毫无疑问，人工智能将使罪犯、恐怖分子和敌对政府更容易做坏事。

This causes some people to propose, _well, in that case, let’s not take the risk, let’s ban AI now before this can happen_. Unfortunately, AI is not some esoteric physical material that is hard to come by, like plutonium. It’s the opposite, it’s the easiest material in the world to come by – math and code.  
这导致一些人提议，好吧，既然如此，我们就不要冒险了，让我们在这种情况发生之前禁止人工智能吧。不幸的是，人工智能并不是像钚那样难以获得的深奥物理材料。恰恰相反，它是世界上最容易获得的材料——数学和代码。

The AI cat is obviously already out of the bag. You can learn how to build AI from thousands of free online courses, books, papers, and videos, and there are outstanding open source implementations proliferating by the _day_. AI is like air – it will be everywhere. The level of totalitarian oppression that would be required to arrest that would be so draconian – a world government monitoring and controlling all computers? jackbooted thugs in black helicopters seizing rogue GPUs? – that we would not have a society left to protect.  
AI猫显然已经出局了。您可以从数以千计的免费在线课程、书籍、论文和视频中学习如何构建 AI，而且优秀的开源实现每天都在激增。人工智能就像空气——它将无处不在。逮捕如此严酷的人所需的极权主义压迫程度——一个监视和控制所有计算机的世界政府？黑色直升机中的长靴暴徒夺取流氓 GPU？ – 我们不会有一个社会需要保护。

So instead, there are two very straightforward ways to address the risk of bad people doing bad things with AI, and these are precisely what we should focus on.  
因此，有两种非常直接的方法可以解决坏人用人工智能做坏事的风险，而这些正是我们应该关注的。

First, we have laws on the books to criminalize most of the bad things that anyone is going to do with AI. Hack into the Pentagon? That’s a crime. Steal money from a bank? That’s a crime. Create a bioweapon? That’s a crime. Commit a terrorist act? That’s a crime. We can simply focus on preventing those crimes when we can, and prosecuting them when we cannot. We don’t even need new laws – I’m not aware of a single actual bad use for AI that’s been proposed that’s not already illegal. And if a new bad use is identified, we ban that use. QED.  
首先，我们有法律将任何人用人工智能做的大多数坏事定为犯罪。入侵五角大楼？那是一种犯罪。从银行偷钱？那是一种犯罪。制造生化武器？那是一种犯罪。实施恐怖行为？那是一种犯罪。我们可以简单地集中精力在力所能及的情况下防止这些罪行，在我们不能的情况下起诉它们。我们甚至不需要新的法律——我不知道有哪一个已经被提议的 AI 的实际不良使用还不是非法的。如果发现新的不良用途，我们将禁止该用途。 QED。

But you’ll notice what I slipped in there – I said we should focus first on _preventing_ AI-assisted crimes before they happen – wouldn’t such prevention mean banning AI? Well, there’s another way to prevent such actions, and that’s by _using AI as a defensive tool_. The same capabilities that make AI dangerous in the hands of bad guys with bad goals make it powerful in the hands of good guys with good goals – specifically the good guys whose job it is to prevent bad things from happening.  
但是你会注意到我在那里漏掉了什么——我说我们应该首先关注在人工智能辅助犯罪发生之前预防它们——这样的预防难道不意味着禁止人工智能吗？好吧，还有另一种方法可以防止此类行为，那就是使用人工智能作为防御工具。使人工智能在有坏目标的坏人手中变得危险的能力，在有好目标的好人手中变得强大——特别是那些工作是防止坏事发生的好人。

For example, if you are worried about AI generating fake people and fake videos, the answer is to build new systems where people can verify [themselves](https://www.biometricupdate.com/202303/worldcoin-says-sdk-lets-you-prove-youre-a-human-online-coins-not-included) and [real content](https://www.wired.com/story/the-blockchain-solution-to-our-deepfake-problems/) via cryptographic signatures. Digital creation and alteration of both real and fake content was already here before AI; the answer is not to ban word processors and Photoshop – or AI – but to use technology to build a system that actually solves the problem.  
例如，如果您担心 AI 会生成假人和假视频，那么答案就是构建新系统，让人们可以通过加密签名验证自己和真实内容。在 AI 出现之前就已经存在了真实和虚假内容的数字创建和更改；答案不是禁止文本处理器和 Photoshop——或人工智能——而是使用技术来构建一个真正解决问题的系统。

And so, second, let’s mount major efforts to use AI for good, legitimate, _defensive_ purposes. Let’s put AI to work in cyberdefense, in biological defense, in hunting terrorists, and in everything else that we do to keep ourselves, our communities, and our nation safe.  
因此，其次，让我们做出重大努力，将 AI 用于好的、合法的防御目的。让我们将 AI 用于网络防御、生物防御、追捕恐怖分子，以及我们为保护我们自己、我们的社区和我们国家的安全所做的一切。

There are already many smart people in and out of government doing exactly this, of course – but if we apply all of the effort and brainpower that’s currently fixated on the futile prospect of _banning_ AI to _using_ AI to protect against bad people doing bad things, I think there’s no question a world infused with AI will be much safer than the world we live in today.  
当然，政府内外已经有很多聪明人在做这件事——但如果我们把目前专注于禁止 AI 的徒劳前景的所有努力和脑力用于使用 AI 来防止坏人做坏事，我认为毫无疑问，一个充满人工智能的世界将比我们今天生活的世界安全得多。

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****The Actual Risk Of Not Pursuing AI With Maximum Force And Speed  
不以最大的力量和速度追求人工智能的实际风险**

There is one final, and real, AI risk that is probably the scariest at all:  
最后一个真实的人工智能风险可能是最可怕的：

AI isn’t just being developed in the relatively free societies of the West, it is also being developed by the Communist Party of the People’s Republic of China.  
人工智能不仅在西方相对自由的社会中得到发展，它也在中华人民共和国共产党中得到发展。

China has a [vastly different vision](https://www.nytimes.com/2018/07/08/business/china-surveillance-technology.html) for AI than we do – they view it as a mechanism for authoritarian population control, full stop. They are not even being secretive about this, they are [very clear about it](https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/), and they are already pursuing their agenda. And they do not intend to limit their AI strategy to China – they intend to [proliferate it all across the world](https://www.cfr.org/china-digital-silk-road/), everywhere they are powering 5G networks, everywhere they are loaning Belt And Road money, everywhere they are providing friendly consumer apps like Tiktok that serve as front ends to their centralized command and control AI.  
中国对人工智能的看法与我们截然不同——他们将其视为专制人口控制的机制，句号。他们甚至对此都没有遮遮掩掩，他们非常清楚，并且已经在进行他们的议程。他们不打算将他们的 AI 战略限制在中国——他们打算在全世界推广它，在他们为 5G 网络提供动力的任何地方，在一带一路贷款的任何地方，在他们提供像 Tiktok 这样的友好消费者应用程序的任何地方作为其集中指挥和控制 AI 的前端。

_The single greatest risk of AI is that China wins global AI dominance and we – the United States and the West – do not.  
人工智能的最大风险是中国赢得了全球人工智能主导地位，而我们——美国和西方——却没有。_

I propose a simple strategy for what to do about this – in fact, the same strategy President Ronald Reagan used to win the first Cold War with the Soviet Union.  
我提出了一个简单的策略来解决这个问题——事实上，罗纳德里根总统用来赢得与苏联的第一次冷战的策略相同。

[“We win, they lose.” “我们赢了，他们输了。”](https://claremontreviewofbooks.com/we-win-they-lose/)

Rather than allowing ungrounded panics around killer AI, “harmful” AI, job-destroying AI, and inequality-generating AI to put us on our back feet, we in the United States and the West should lean into AI as hard as we possibly can.  
与其让围绕杀手人工智能、“有害”人工智能、破坏工作的人工智能和造成不平等的人工智能的毫无根据的恐慌让我们退缩，我们在美国和西方国家应该尽可能地依靠人工智能.

_We should seek to win the race to global AI technological superiority and ensure that China does not.  
我们应该寻求赢得全球人工智能技术优势的竞赛，并确保中国不会。_

In the process, we should drive AI into our economy and society as fast and hard as we possibly can, in order to maximize its gains for economic productivity and human potential.  
在此过程中，我们应该尽可能快地推动人工智能进入我们的经济和社会，以最大限度地提高经济生产力和人类潜能。

_This_ is the best way both to offset the _real_ AI risks and to ensure that our way of life is not displaced by the [much darker Chinese vision](https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/)  
这是抵消真正的人工智能风险和确保我们的生活方式不被更黑暗的中国愿景所取代的最佳方式.

## **

#### TABLE OF CONTENTS

-   [AI can make everything we care about better](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--1)
-   [Why the panic?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--2)
-   [The Baptists and Bootleggers of AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--3)
-   [AI Risk #1: Will AI kill us all?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--4)
-   [AI Risk #2: Will AI ruin our society?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--5)
-   [AI Risk #3: Will AI take all our jobs?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--6)
-   [AI Risk #4: Will AI lead to crippling inequality?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--7)
-   [AI Risk #5: Will AI lead to people doing bad things?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--8)
-   [The actual risk of not pursuing AI](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--9)
-   [What is to be done?](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--10)
-   [Legends and heroes](https://a16z.com/2023/06/06/ai-will-save-the-world/#section--11)



****What Is To Be Done? 什么是要做？**

I propose a simple plan: 我提出一个简单的计划：

-   Big AI companies should be allowed to build AI as fast and aggressively as they can – but _not_ allowed to achieve regulatory capture, _not_ allowed to establish a government-protect cartel that is insulated from market competition due to incorrect claims of AI risk. This will maximize the technological and societal payoff from the amazing capabilities of these companies, which are jewels of modern capitalism.  
    应该允许大型 AI 公司尽可能快速和积极地构建 AI——但不允许实现监管俘获，不允许创建受政府保护的卡特尔，由于对 AI 风险的不正确声明而不受市场竞争的影响。这将使这些公司的惊人能力最大化技术和社会回报，这些公司是现代资本主义的瑰宝。
-   Startup AI companies should be allowed to build AI as fast and aggressively as _they_ can. They should neither confront government-granted protection of big companies, nor should they receive government assistance. They should simply be allowed to compete. If and as startups _don’t_ succeed, their presence in the market will also continuously motivate big companies to be their best – our economies and societies win either way.  
    应该允许初创人工智能公司尽可能快速和积极地构建人工智能。他们既不应该对抗政府给予大公司的保护，也不应该接受政府的援助。他们应该被允许竞争。如果初创公司没有成功，它们在市场上的存在也会不断激励大公司做到最好——无论哪种方式，我们的经济和社会都会获胜。
-   Open source AI should be allowed to freely proliferate and compete with both big AI companies and startups. There should be no regulatory barriers to open source whatsoever. Even when open source does not beat companies, its widespread availability is a boon to students all over the world who want to learn how to build and use AI to become part of the technological future, and will ensure that AI is available to everyone who can benefit from it no matter who they are or how much money they have.  
    应该允许开源 AI 自由扩散并与大型 AI 公司和初创公司竞争。开源不应有任何监管障碍。即使开源没有打败公司，它的广泛可用性对世界各地想要学习如何构建和使用 AI 以成为技术未来的一部分的学生来说也是一个福音，并将确保 AI 可供每个有能力的人使用无论他们是谁或他们有多少钱，都可以从中受益。
-   To offset the risk of bad people doing bad things with AI, governments working in partnership with the private sector should vigorously engage in each area of potential risk to use AI to maximize society’s defensive capabilities. This shouldn’t be limited to AI-enabled risks but also more general problems such as malnutrition, disease, and climate. AI can be an incredibly powerful tool for solving problems, and we should embrace it as such.  
    为了抵消坏人利用人工智能做坏事的风险，政府与私营部门合作应积极参与每个潜在风险领域，利用人工智能最大限度地提高社会的防御能力。这不应仅限于人工智能带来的风险，还应包括营养不良、疾病和气候等更普遍的问题。人工智能可以成为解决问题的强大工具，我们应该拥抱它。
-   To prevent the risk of China achieving global AI dominance, we should use the full power of our private sector, our scientific establishment, and our governments in concert to drive American and Western AI to absolute global dominance, including ultimately inside China itself. We win, they lose.  
    为了防止中国实现全球人工智能主导地位的风险，我们应该利用我们的私营部门、我们的科学机构和我们的政府的全部力量，共同推动美国和西方人工智能在全球范围内取得绝对主导地位，包括最终在中国本土。我们赢了，他们输了。

And that is how we use AI to save the world.  
这就是我们使用 AI 拯救世界的方式。

It’s time to build. 是时候建造了。

## **Legends and Heroes 传奇与英雄**

I close with two simple statements.  
我以两个简单的陈述结束。

The development of AI started in the 1940’s, [simultaneous with the invention of the computer](https://www.amazon.com/Rise-Machines-Cybernetic-Thomas-Rid/dp/0393286002). The first scientific paper on neural networks – the architecture of the AI we have today – was [published in 1943](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf). Entire generations of AI scientists over the last 80 years were born, went to school, worked, and in many cases passed away without seeing the payoff that we are receiving now. They are legends, every one.  
人工智能的发展始于 1940 年代，与计算机的发明同时进行。第一篇关于神经网络的科学论文——我们今天拥有的人工智能的架构——发表于 1943 年。在过去的 80 年里，整整几代人工智能科学家出生、上学、工作，在许多情况下去世时都没有看到我们现在收到的回报。他们都是传奇，每一个人。

Today, growing legions of engineers – many of whom are young and may have had grandparents or even great-grandparents involved in the creation of the ideas behind AI – are working to make AI a reality, against a wall of fear-mongering and doomerism that is attempting to paint them as reckless villains. I do not believe they are reckless or villains. They are heroes, every one. My firm and I are thrilled to back as many of them as we can, and we will stand alongside them and their work 100%.  
今天，越来越多的工程师——其中许多人很年轻，可能有祖父母甚至曾祖父母参与了 AI 背后思想的创造——正在努力使 AI 成为现实，反对散布恐惧和末日论的墙试图把他们描绘成鲁莽的恶棍。我不相信他们是鲁莽的或恶棍。他们都是英雄，每一个人。我和我的公司很高兴能尽可能多地支持他们，我们将 100% 支持他们和他们的工作。

\* \* \*

_The views expressed here are those of the individual AH Capital Management, L.L.C. (“a16z”) personnel quoted and are not the views of a16z or its affiliates. Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z. While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the current or enduring accuracy of the information or its appropriateness for a given situation. In addition, this content may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.  
此处表达的观点是 AH Capital Management, L.L.C. 个人的观点。 (“a16z”) 人员引用但不代表 a16z 或其附属公司的观点。此处包含的某些信息是从第三方来源获得的，包括来自 a16z 管理的基金的投资组合公司。虽然从被认为可靠的来源获取信息，a16z 并未独立核实此类信息，也不对信息当前或持久的准确性或其对特定情况的适用性做出任何陈述。此外，此内容可能包含第三方广告； a16z 没有审查过此类广告，也不认可其中包含的任何广告内容。_

_This content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice. You should consult your own advisers as to those matters. References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services. Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z. (An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results. A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at https://a16z.com/investments/.  
此内容仅供参考，不应作为法律、商业、投资或税务建议。您应该就这些事项咨询您自己的顾问。对任何证券或数字资产的引用仅供说明之用，并不构成投资建议或提供投资咨询服务的要约。此外，本内容不针对或旨在供任何投资者或潜在投资者使用，并且在任何情况下都不得在决定投资 a16z 管理的任何基金时予以依赖。 （投资 a16z 基金的要约只能通过私募备忘录、认购协议和任何此类基金的其他相关文档进行，并且应完整阅读。）提及、提及或提及的任何投资或投资组合公司所描述的并不代表对 a16z 管理的车辆的所有投资，并且不能保证这些投资将盈利或未来进行的其他投资将具有类似的特征或结果。由 Andreessen Horowitz 管理的基金进行的投资清单（不包括发行人未允许 a16z 公开披露的投资以及未宣布的公开交易数字资产投资）可在 https://a16z.com/investments 获取/._

_Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision. Past performance is not indicative of future results. The content speaks only as of the date indicated. Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others. Please see https://a16z.com/disclosures for additional important information.  
其中提供的图表仅供参考，在做出任何投资决定时不应依赖。过去的表现并不预示未来的结果。内容仅在指定日期有效。这些材料中表达的任何预测、估计、预测、目标、前景和/或意见如有更改，恕不另行通知，并且可能与其他人表达的意见不同或相反。请参阅 https://a16z.com/disclosures 了解更多重要信息。_
